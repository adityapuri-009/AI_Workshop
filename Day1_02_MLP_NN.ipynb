{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day1_02_MLP_NN.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adityapuri-009/AI_Workshop/blob/master/Day1_02_MLP_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsB552XtvHs2",
        "colab_type": "text"
      },
      "source": [
        "## Step 1\n",
        "\n",
        "1. Define parameters - Network and hyper-parameters\n",
        "2. IF Computation Graph\n",
        "3. Multilayer perceptron\n",
        "4. W, b dictionaries\n",
        "5. pred label\n",
        "6. cost & optimizers\n",
        "7. Init session\n",
        "8. Run the session and model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BTNpLxFvG-A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "dc28e0ca-740f-452e-bdee-8ddcaca93607"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.examples.tutorials.mnist import input_data"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlqF1tSAxVpF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "6cb09364-e7c4-4acd-a413-122172809a27"
      },
      "source": [
        "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-3-83231f068ae1>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e80dmVQGxbUG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyperparameter\n",
        "learning_rate = 0.001\n",
        "training_epochs = 100\n",
        "batch_size = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayeaW8o7xr6E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Network Parameters\n",
        "n_hidden_1 = 256\n",
        "n_hidden_2 = 256\n",
        "n_input = 784\n",
        "n_classes = 10\n",
        "n_samples = mnist.train.num_examples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQsXKb4myBif",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TF graph inputs / placeholders\n",
        "x = tf.placeholder('float', [None, n_input])\n",
        "y = tf.placeholder('float', [None, n_classes])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eD-Q7VJP8ofW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# weights and biases\n",
        "weights = {\n",
        "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
        "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
        "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
        "}\n",
        "\n",
        "biases = {\n",
        "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
        "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
        "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvmBG1ekyaBB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#MLP\n",
        "def mlp(x, weights, biases):\n",
        "  layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
        "  layer_1 = tf.nn.relu(layer_1)\n",
        "\n",
        "  layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
        "  layer_2 = tf.nn.relu(layer_2)\n",
        "  \n",
        "  # final output\n",
        "  out_layer = tf.add(tf.matmul(layer_2, weights['out']), biases['out'])\n",
        "  return out_layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arCBIVj31GtP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predicted label\n",
        "pred = mlp(x, weights, biases)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGln-DOr-fAV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# costs / optimizers\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels = y, logits = pred))\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0_celIi1Xv0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# init\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EfXLVd81m-4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4985884f-cbef-426a-ea14-6cacb3eda694"
      },
      "source": [
        "sess = tf.InteractiveSession()\n",
        "\n",
        "sess.run(init)\n",
        "\n",
        "for epoch in range(training_epochs):\n",
        "  avg_cost = 0.0\n",
        "  total_batch = int(n_samples/batch_size)\n",
        "\n",
        "  #loop over all batches\n",
        "  for i in range(total_batch):\n",
        "    #grab the next batch\n",
        "    batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
        "    #feed in the dict to minimize & optimize cost loss\n",
        "    _, c = sess.run([optimizer, cost], feed_dict={x:batch_x, y:batch_y})\n",
        "\n",
        "    #compute avg loss\n",
        "    avg_cost += c / total_batch\n",
        "\n",
        "  print(\"Epoch: {}  cost={: .4f}\".format(epoch+1, avg_cost))\n",
        "print(\"Model has completed {} Epochs of training\".format (training_epochs))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1  cost= 187.2397\n",
            "Epoch: 2  cost= 44.7617\n",
            "Epoch: 3  cost= 28.5620\n",
            "Epoch: 4  cost= 20.4319\n",
            "Epoch: 5  cost= 15.1384\n",
            "Epoch: 6  cost= 11.5391\n",
            "Epoch: 7  cost= 8.5903\n",
            "Epoch: 8  cost= 6.5269\n",
            "Epoch: 9  cost= 5.0886\n",
            "Epoch: 10  cost= 3.8410\n",
            "Epoch: 11  cost= 2.8959\n",
            "Epoch: 12  cost= 2.2557\n",
            "Epoch: 13  cost= 1.7040\n",
            "Epoch: 14  cost= 1.2564\n",
            "Epoch: 15  cost= 1.0341\n",
            "Epoch: 16  cost= 0.7423\n",
            "Epoch: 17  cost= 0.6312\n",
            "Epoch: 18  cost= 0.5773\n",
            "Epoch: 19  cost= 0.4791\n",
            "Epoch: 20  cost= 0.3674\n",
            "Epoch: 21  cost= 0.3467\n",
            "Epoch: 22  cost= 0.3743\n",
            "Epoch: 23  cost= 0.3047\n",
            "Epoch: 24  cost= 0.3141\n",
            "Epoch: 25  cost= 0.2769\n",
            "Epoch: 26  cost= 0.2326\n",
            "Epoch: 27  cost= 0.2452\n",
            "Epoch: 28  cost= 0.1692\n",
            "Epoch: 29  cost= 0.2918\n",
            "Epoch: 30  cost= 0.3106\n",
            "Epoch: 31  cost= 0.2077\n",
            "Epoch: 32  cost= 0.1746\n",
            "Epoch: 33  cost= 0.1862\n",
            "Epoch: 34  cost= 0.2259\n",
            "Epoch: 35  cost= 0.1883\n",
            "Epoch: 36  cost= 0.1702\n",
            "Epoch: 37  cost= 0.2064\n",
            "Epoch: 38  cost= 0.1705\n",
            "Epoch: 39  cost= 0.1766\n",
            "Epoch: 40  cost= 0.1587\n",
            "Epoch: 41  cost= 0.1647\n",
            "Epoch: 42  cost= 0.1507\n",
            "Epoch: 43  cost= 0.1678\n",
            "Epoch: 44  cost= 0.1977\n",
            "Epoch: 45  cost= 0.1271\n",
            "Epoch: 46  cost= 0.1841\n",
            "Epoch: 47  cost= 0.1259\n",
            "Epoch: 48  cost= 0.1434\n",
            "Epoch: 49  cost= 0.1496\n",
            "Epoch: 50  cost= 0.1694\n",
            "Epoch: 51  cost= 0.1187\n",
            "Epoch: 52  cost= 0.1296\n",
            "Epoch: 53  cost= 0.1394\n",
            "Epoch: 54  cost= 0.1141\n",
            "Epoch: 55  cost= 0.1080\n",
            "Epoch: 56  cost= 0.1395\n",
            "Epoch: 57  cost= 0.1275\n",
            "Epoch: 58  cost= 0.1410\n",
            "Epoch: 59  cost= 0.0936\n",
            "Epoch: 60  cost= 0.1033\n",
            "Epoch: 61  cost= 0.1400\n",
            "Epoch: 62  cost= 0.1477\n",
            "Epoch: 63  cost= 0.0841\n",
            "Epoch: 64  cost= 0.0905\n",
            "Epoch: 65  cost= 0.1151\n",
            "Epoch: 66  cost= 0.1262\n",
            "Epoch: 67  cost= 0.0837\n",
            "Epoch: 68  cost= 0.1095\n",
            "Epoch: 69  cost= 0.1377\n",
            "Epoch: 70  cost= 0.0931\n",
            "Epoch: 71  cost= 0.0970\n",
            "Epoch: 72  cost= 0.1142\n",
            "Epoch: 73  cost= 0.0741\n",
            "Epoch: 74  cost= 0.0912\n",
            "Epoch: 75  cost= 0.0969\n",
            "Epoch: 76  cost= 0.1281\n",
            "Epoch: 77  cost= 0.0669\n",
            "Epoch: 78  cost= 0.1150\n",
            "Epoch: 79  cost= 0.0931\n",
            "Epoch: 80  cost= 0.0738\n",
            "Epoch: 81  cost= 0.1004\n",
            "Epoch: 82  cost= 0.1403\n",
            "Epoch: 83  cost= 0.0842\n",
            "Epoch: 84  cost= 0.0663\n",
            "Epoch: 85  cost= 0.0790\n",
            "Epoch: 86  cost= 0.0930\n",
            "Epoch: 87  cost= 0.0731\n",
            "Epoch: 88  cost= 0.0802\n",
            "Epoch: 89  cost= 0.0798\n",
            "Epoch: 90  cost= 0.0949\n",
            "Epoch: 91  cost= 0.1079\n",
            "Epoch: 92  cost= 0.0775\n",
            "Epoch: 93  cost= 0.1032\n",
            "Epoch: 94  cost= 0.0888\n",
            "Epoch: 95  cost= 0.0599\n",
            "Epoch: 96  cost= 0.0715\n",
            "Epoch: 97  cost= 0.0848\n",
            "Epoch: 98  cost= 0.0986\n",
            "Epoch: 99  cost= 0.1072\n",
            "Epoch: 100  cost= 0.0590\n",
            "Model has completed 100 Epochs of training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQhH5O_h4Qnp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model testing and evaluation\n",
        "correct_predictions = tf.equal(tf.argmax(pred,1), tf.argmax(y, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aYGN46dA3Mt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "39f95b7c-04e3-4766-cd2a-2eb3fbff2dd2"
      },
      "source": [
        "print(correct_predictions[0])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"strided_slice:0\", shape=(), dtype=bool)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJBBSJJABLb9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct_predictions = tf.cast(correct_predictions, \"float\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucKP5_XiBTZ2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c927b789-8f8e-43f7-968c-67b4b2de1d1b"
      },
      "source": [
        "accuracy = tf.reduce_mean(correct_predictions)\n",
        "print(\"Accuracy: \", accuracy.eval({x:mnist.test.images,\n",
        "                                  y:mnist.test.labels}))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.9681\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKqGXhYNBZt-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}